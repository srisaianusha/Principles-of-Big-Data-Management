import org.apache.spark.SparkContext
import org.apache.spark.SparkConf


/**
  * Created by Sri Sai Anusha on 03-04-2017.
  */
object BestTime {

  def main(args: Array[String]): Unit = {
    System.setProperty("hadoop.home.dir","C:\\Users\\Sri Sai Anusha\\Desktop\\Winutils")
    val conf = new SparkConf().setAppName("Queries").setMaster("local[*]")
    val sc = new SparkContext(conf)
    val sqlContext = new org.apache.spark.sql.SQLContext(sc)

    val tweet= sqlContext.read.json("D:/Sem II/PB/Project 2/tweets.json")
    tweet.createOrReplaceTempView("tweets")

    val day_data = sqlContext.sql("SELECT substring(user.created_at,1,3) as day from tweets where text is not null")
    day_data.createOrReplaceTempView("day_data")
    val days_final = sqlContext.sql(
      """ SELECT Case
        |when day LIKE '%Mon%' then 'MONDAY'
        |when day LIKE '%Tue%' then 'TUESDAY'
        |when day LIKE '%Wed%' then 'WEDNESDAY'
        |when day LIKE '%Thu%' then 'THURSDAY'
        |when day LIKE '%Fri%' then 'FRIDAY'
        |when day LIKE '%Sat%' then 'SATURDAY'
        |when day LIKE '%Sun%' then 'SUNDAY'
        | else
        | null
        | end as day1 from day_data where day is not null""".stripMargin)

    days_final.createOrReplaceTempView("days_final")
    val res = sqlContext.sql("SELECT day1 as Day,Count(*) as Day_Count FROM days_final WHERE day1 is not null GROUP BY day1 ORDER BY count(*) DESC")
    res.show()


  }
}
